{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaicolLojano/Marcos-de-Referencia-para-Big-Data/blob/main/UNIDAD%203%20Y%204/AnaliticaEscalablePySparkEjercicios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caso práctico de Analítica Escalable (Ejercicios) #"
      ],
      "metadata": {
        "id": "WgBT__xbN5uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook, se van a realizar los ejercicios del módulo. En lugar de tener contenido teórico y descripciones, se dejarán únicamente las celdas de código necesarias para su ejecución.\n",
        "\n",
        "Para completar los ejercicios, hay que codificar y ejecutar la solución en las celdas que se encuentran justo debajo de los enunciados de los ejercicios.\n",
        "\n",
        "Una vez se haya terminado, en el menú de la izquiera, a la hora de seleccionar el notebook, si se le hace click a la flecha que se encuentra en la derecha, se puede exportar al notebook. Hay que exportarlo en formato DBC (Databricks Notebook) como en HTML."
      ],
      "metadata": {
        "id": "f4QjtMq0N5uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y668gNrIOnD-",
        "outputId": "699359fe-b6f4-4109-b0ae-2b95cd347c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=1f88fc8772b0e3766d4215b70936eb664a1aa6d6736b11a59ac6ae56400200fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Crear una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"CardiacDataAnalysis\").getOrCreate()\n",
        "\n",
        "# Acceder a la versión de Spark\n",
        "print(spark.version)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ypVetTN5ur",
        "outputId": "3cdd07d0-6d0b-4f7a-fdaa-b8174618edff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.1\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los ejercicios consistirán en añadir nuevas funcionalidades, o ejecutar nuevo código, sobre el Notebook que contiene toda la teoría vista en el módulo. Por ello, gran parte del código que se encuentra dentro del notebook de contenido teórico se encontrará aquí de nuevo, pero se pedirá nuevo código."
      ],
      "metadata": {
        "id": "fzojhQCON5ut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando los datos ##"
      ],
      "metadata": {
        "id": "4rsU5fqSN5ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Leer el archivo CSV\n",
        "df = pd.read_csv('/content/heart.csv')\n",
        "\n",
        "# Mostrar las primeras filas del dataframe\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1e0WwL-BN5ut",
        "outputId": "370adbf2-ab70-45d2-e543-e97897445ba0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ed98253-eaad-4567-a615-608c9e21fb5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ed98253-eaad-4567-a615-608c9e21fb5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ed98253-eaad-4567-a615-608c9e21fb5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ed98253-eaad-4567-a615-608c9e21fb5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca760451-b4ee-40ab-b014-676040ede61b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca760451-b4ee-40ab-b014-676040ede61b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca760451-b4ee-40ab-b014-676040ede61b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          46,\n          66,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          104,\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          277,\n          169\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          159,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1.9,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def score_to_string(score):\n",
        "  if score < 5:\n",
        "    return \"Bad\"\n",
        "  elif score < 7:\n",
        "    return \"Normal\"\n",
        "  elif score < 9:\n",
        "    return \"Good\"\n",
        "  elif score < 10:\n",
        "    return \"Excellent\"\n",
        "  else:\n",
        "    return \"Perfect\"\n",
        "\n",
        "def score_to_evaluation(score_string):\n",
        "  score_dict = {\n",
        "    \"Bad\": 0,\n",
        "    \"Normal\": 1,\n",
        "    \"Good\": 2,\n",
        "    \"Excellent\": 3,\n",
        "    \"Perfect\": 4\n",
        "  }\n",
        "  return score_dict.get(score_string, None)"
      ],
      "metadata": {
        "id": "ZJGKOHCbN5ut"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrames en Spark: SparkSQL. ##"
      ],
      "metadata": {
        "id": "hPXFLircN5uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_sql = spark.read.format(\"csv\")\\\n",
        "         .option(\"header\", \"true\")\\\n",
        "         .option(\"inferSchema\", \"true\")\\\n",
        "         .load(\"/content/heart.csv\")"
      ],
      "metadata": {
        "id": "hmFRWbFXN5uu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "\n",
        "score_string_udf = udf(score_to_string, StringType())\n",
        "score_evaluation_udf = udf(score_to_evaluation, IntegerType())"
      ],
      "metadata": {
        "id": "pQRHGyRIN5uu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_sql.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7kXAM2FS66-",
        "outputId": "443cc028-cc1a-4934-b916-0b291f57ab91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: double (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar las UDFs en la coluumna chol\n",
        "df_spark_sql = df_spark_sql.withColumn('score_string', score_string_udf(df_spark_sql[\"chol\"]))\n",
        "df_spark_sql = df_spark_sql.withColumn('score_evaluation', score_evaluation_udf(df_spark_sql[\"score_string\"]))\n"
      ],
      "metadata": {
        "id": "Hu1joMwDN5uv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función para redondear el valor\n",
        "def round_oldpeak(oldpeak):\n",
        "    return int(round(oldpeak)) if oldpeak is not None else None\n",
        "\n",
        "# Convertir la función a una UDF\n",
        "round_oldpeak_udf = udf(round_oldpeak, IntegerType())\n",
        "\n",
        "# Aplicar la UDF a la columna 'oldpeak'\n",
        "df_spark_sql = df_spark_sql.withColumn(\"rounded_oldpeak\", round_oldpeak_udf(df_spark_sql[\"oldpeak\"]))"
      ],
      "metadata": {
        "id": "06NPo8HmN5uv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 1: Crear un bucle que muestre todas las columnas del DataFrame, junto con sus tipos. También puedes pintar el esquema del Dataframe. ###"
      ],
      "metadata": {
        "id": "_PDwZ3IEN5uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejericicio\n",
        "print(\"Primero imprimimos el esquema:\")\n",
        "print(df_spark_sql.printSchema())\n",
        "print(\"Ahora hacemos el bucle que muestra las columnas y tipos del dataFrame\")\n",
        "for name, dtype in df_spark_sql.dtypes:\n",
        "  print(name, \" --> \",dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPhhVOkqN5uv",
        "outputId": "0c30fccc-4167-4d0a-d2c1-be03af36bd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primero imprimimos el esquema:\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: double (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_string: string (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            "\n",
            "None\n",
            "Ahora hacemos el bucle que muestra las columnas y tipos del dataFrame\n",
            "age  -->  int\n",
            "sex  -->  int\n",
            "cp  -->  int\n",
            "trestbps  -->  int\n",
            "chol  -->  int\n",
            "fbs  -->  int\n",
            "restecg  -->  int\n",
            "thalach  -->  int\n",
            "exang  -->  int\n",
            "oldpeak  -->  double\n",
            "slope  -->  int\n",
            "ca  -->  int\n",
            "thal  -->  int\n",
            "target  -->  int\n",
            "score_string  -->  string\n",
            "score_evaluation  -->  int\n",
            "rounded_oldpeak  -->  int\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 2: Realizar un muestreo de 10 valores únicos de nombres de hoteles. Ordénalos alfanuméricamente de forma ascendente (primero los números 0-9, después A-Z). ###"
      ],
      "metadata": {
        "id": "bbPQ36c8N5uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "df_spark_sql.select('target').distinct().limit(10).orderBy(\"target\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "varQYE10N5uw",
        "outputId": "d1d9c281-23e5-4669-844b-39063f15dacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|target|\n",
            "+------+\n",
            "|     0|\n",
            "|     1|\n",
            "+------+\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 3: Transformamos la columna *oldpeak* al tipo Float."
      ],
      "metadata": {
        "id": "GzTsBX1VN5uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformación de la columna sin utilizar UDF.\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "# Convertir la columna 'oldpeak' a FloatType\n",
        "df_new_aux = df_spark_sql.withColumn(\"oldpeak\", df_spark_sql[\"oldpeak\"].cast(FloatType()))\n",
        "\n",
        "# Actualizar el DataFrame original\n",
        "df_spark_sql = df_new_aux\n",
        "\n",
        "# Comprobamos que ha cambiado\n",
        "print('  ----  Comprobamos que ha cambiado ------ ')\n",
        "df_spark_sql.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJIDRT7pN5uy",
        "outputId": "8312d4db-c79f-4971-a50d-4f16f0c15f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ----  Comprobamos que ha cambiado ------ \n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_string: string (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "splits = df_spark_sql.randomSplit([0.67, 0.33])\n",
        "df_spark_sql_train = splits[0].dropna()\n",
        "df_spark_sql_test = splits[1].dropna()\n",
        "print(df_spark_sql_train.count())\n",
        "print(df_spark_sql_test.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wl1WgWfN5uy",
        "outputId": "4bcdae3b-a9c7-4c30-bbe1-413a68835015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188\n",
            "115\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 4: # 1. ¿Cuántas personas tienen una `thalach` (máxima frecuencia cardíaca alcanzada) por encima de 150?"
      ],
      "metadata": {
        "id": "csMwRgLlN5uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "BTia4ItTAfE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "thalach_above_150 = df[df[\"thalach\"] > 150].shape[0]\n",
        "print(f\"Personas con thalach > 150: {thalach_above_150}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VsRbM93N5uy",
        "outputId": "7f4f67db-bee6-4f81-bc9a-afa5138e99fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Personas con thalach > 150: 164\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 5: Obtener el chol con mayor puntuación media, descartando todos los que tengan una puntuación por encima de Good. (Utilizar el dataset de Train) ###"
      ],
      "metadata": {
        "id": "6_koJn8mN5uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "# Agrupar por 'cp' y calcular el promedio de 'chol'\n",
        "df_puntuacion = df.groupby('cp')['chol'].mean().reset_index()\n",
        "\n",
        "# Renombrar la columna de promedio\n",
        "df_puntuacion.rename(columns={'chol': 'avg(chol)'}, inplace=True)\n",
        "\n",
        "# Ordenar por 'avg(chol)' en orden descendente y mostrar los 10 primeros resultados\n",
        "df_puntuacion_sorted = df_puntuacion.sort_values(by='avg(chol)', ascending=False)\n",
        "\n",
        "top_10 = df_puntuacion_sorted.head(10)\n",
        "\n",
        "print(\"Top 10 grupos con mayor promedio de colesterol:\")\n",
        "print(top_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8bSh1B5N5uz",
        "outputId": "a2685330-7955-4de0-90da-7340b61e46a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 grupos con mayor promedio de colesterol:\n",
            "   cp   avg(chol)\n",
            "0   0  250.132867\n",
            "1   1  244.780000\n",
            "2   2  243.172414\n",
            "3   3  237.130435\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning en Apache Spark: Spark MLLib y Spark ML #"
      ],
      "metadata": {
        "id": "EghSCNOUN5uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación Supervisada: Árboles de decisión ##"
      ],
      "metadata": {
        "id": "b6-G4TWVN5uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 6.1: Volver a observar todas las columnas del dataframe, para identificar las que sean categóricas. ###"
      ],
      "metadata": {
        "id": "zG-FoU-yN5uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "print(\"   ---------- Primero imprimimos el esquema: -----------\")\n",
        "print(df_spark_sql.printSchema())\n",
        "print(\"   ---------- Despues imprimimos algunos datos: -----------\")\n",
        "df_spark_sql.select('*').limit(100).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjOoMpnFN5uz",
        "outputId": "5a2f4fa2-a43e-42f4-ee8c-78ac82adb2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Primero imprimimos el esquema: -----------\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_string: string (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            "\n",
            "None\n",
            "   ---------- Despues imprimimos algunos datos: -----------\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+------------+----------------+---------------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|score_string|score_evaluation|rounded_oldpeak|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+------------+----------------+---------------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|     Perfect|               4|              2|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|     Perfect|               4|              4|\n",
            "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 57|  1|  0|     140| 192|  0|      1|    148|    0|    0.4|    1|  0|   1|     1|     Perfect|               4|              0|\n",
            "| 56|  0|  1|     140| 294|  0|      0|    153|    0|    1.3|    1|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 44|  1|  1|     120| 263|  0|      1|    173|    0|    0.0|    2|  0|   3|     1|     Perfect|               4|              0|\n",
            "| 52|  1|  2|     172| 199|  1|      1|    162|    0|    0.5|    2|  0|   3|     1|     Perfect|               4|              0|\n",
            "| 57|  1|  2|     150| 168|  0|      1|    174|    0|    1.6|    2|  0|   2|     1|     Perfect|               4|              2|\n",
            "| 54|  1|  0|     140| 239|  0|      1|    160|    0|    1.2|    2|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 48|  0|  2|     130| 275|  0|      1|    139|    0|    0.2|    2|  0|   2|     1|     Perfect|               4|              0|\n",
            "| 49|  1|  1|     130| 266|  0|      1|    171|    0|    0.6|    2|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 64|  1|  3|     110| 211|  0|      0|    144|    1|    1.8|    1|  0|   2|     1|     Perfect|               4|              2|\n",
            "| 58|  0|  3|     150| 283|  1|      0|    162|    0|    1.0|    2|  0|   2|     1|     Perfect|               4|              1|\n",
            "| 50|  0|  2|     120| 219|  0|      1|    158|    0|    1.6|    1|  0|   2|     1|     Perfect|               4|              2|\n",
            "| 58|  0|  2|     120| 340|  0|      1|    172|    0|    0.0|    2|  0|   2|     1|     Perfect|               4|              0|\n",
            "| 66|  0|  3|     150| 226|  0|      1|    114|    0|    2.6|    0|  0|   2|     1|     Perfect|               4|              3|\n",
            "| 43|  1|  0|     150| 247|  0|      1|    171|    0|    1.5|    2|  0|   2|     1|     Perfect|               4|              2|\n",
            "| 69|  0|  3|     140| 239|  0|      1|    151|    0|    1.8|    2|  2|   2|     1|     Perfect|               4|              2|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+------------+----------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 6.2: Eliminar, de los dataframes df_spark_sql_train y df_spark_sql test, las variables 'Hotel_Address', 'Hotel_Name', 'Tags', 'Positive Review', 'Negative_Review' y 'score_string'. Llamarlos: df_DT_train y df_DT_test. ###"
      ],
      "metadata": {
        "id": "-ATA-7diN5uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En nuestro caso no eliminaremos ninguna de las columnas descritas ya que todas parecen relevantes para el análisis de datos y la predicción del riesgo cardiovascular."
      ],
      "metadata": {
        "id": "Fu8DUspwHmks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "df_DT_train = df_spark_sql_train.drop('Hotel_Address', 'Hotel_Name', 'Tags', 'Positive_Review', 'Negative_Review', 'score_string')\n",
        "print(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\")\n",
        "print(df_DT_train.printSchema())\n",
        "df_DT_test = df_spark_sql_test.drop('Hotel_Address', 'Hotel_Name', 'Tags', 'Positive_Review', 'Negative_Review', 'score_string')\n",
        "print(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\")\n",
        "print(df_DT_test.printSchema())"
      ],
      "metadata": {
        "id": "cY4E-sWhN5u0",
        "outputId": "afc70bf8-e360-4c2f-d2ae-6ca6aa04d98e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            "\n",
            "None\n",
            "   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 7: Para cada columa restante que sea String (' cp, fbs, restecg, slope, thal'), aplicar un StringIndexer(), devolviendo como resultado la misma columna, pero con su nombre acabando en _index. Sobreescribir ambos dataframes.  ###"
      ],
      "metadata": {
        "id": "zDi53UJ6N5u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "print(\"   ---------- Definimos un indexer para cada columna categórica -----------\")\n",
        "\n",
        "# Definir indexers para las columnas categóricas\n",
        "indexerCP = StringIndexer(inputCol=\"cp\", outputCol=\"cp_index\")\n",
        "indexerFBS = StringIndexer(inputCol=\"fbs\", outputCol=\"fbs_index\")\n",
        "indexerRestECG = StringIndexer(inputCol=\"restecg\", outputCol=\"restecg_index\")\n",
        "indexerSlope = StringIndexer(inputCol=\"slope\", outputCol=\"slope_index\")\n",
        "indexerThal = StringIndexer(inputCol=\"thal\", outputCol=\"thal_index\")\n",
        "\n",
        "print(\"   ---------- Ejecutamos los indexers sobre ambos DataFrames -----------\")\n",
        "\n",
        "# Aplicar los indexers a df_DT_train\n",
        "df_DT_train = indexerCP.fit(df_DT_train).transform(df_DT_train)\n",
        "df_DT_train = indexerFBS.fit(df_DT_train).transform(df_DT_train)\n",
        "df_DT_train = indexerRestECG.fit(df_DT_train).transform(df_DT_train)\n",
        "df_DT_train = indexerSlope.fit(df_DT_train).transform(df_DT_train)\n",
        "df_DT_train = indexerThal.fit(df_DT_train).transform(df_DT_train)\n",
        "\n",
        "# Aplicar los indexers a df_DT_test\n",
        "df_DT_test = indexerCP.fit(df_DT_test).transform(df_DT_test)\n",
        "df_DT_test = indexerFBS.fit(df_DT_test).transform(df_DT_test)\n",
        "df_DT_test = indexerRestECG.fit(df_DT_test).transform(df_DT_test)\n",
        "df_DT_test = indexerSlope.fit(df_DT_test).transform(df_DT_test)\n",
        "df_DT_test = indexerThal.fit(df_DT_test).transform(df_DT_test)\n",
        "\n",
        "print(\"   ---------- Comprobamos que se han creado las columnas en df_DT_train -----------\")\n",
        "df_DT_train.select('cp', 'cp_index', 'fbs', 'fbs_index', 'restecg', 'restecg_index', 'slope', 'slope_index', 'thal', 'thal_index').limit(100).show()\n",
        "\n",
        "print(\"   ---------- Comprobamos que se han creado las columnas en df_DT_test -----------\")\n",
        "df_DT_test.select('cp', 'cp_index', 'fbs', 'fbs_index', 'restecg', 'restecg_index', 'slope', 'slope_index', 'thal', 'thal_index').limit(100).show()\n"
      ],
      "metadata": {
        "id": "kQBu3Nw1N5u0",
        "outputId": "9fe0444f-7eea-4c3a-a5dd-d5c825e65c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Definimos un indexer para cada columna categórica -----------\n",
            "   ---------- Ejecutamos los indexers sobre ambos DataFrames -----------\n",
            "   ---------- Comprobamos que se han creado las columnas en df_DT_train -----------\n",
            "+---+--------+---+---------+-------+-------------+-----+-----------+----+----------+\n",
            "| cp|cp_index|fbs|fbs_index|restecg|restecg_index|slope|slope_index|thal|thal_index|\n",
            "+---+--------+---+---------+-------+-------------+-----+-----------+----+----------+\n",
            "|  3|     3.0|  0|      0.0|      0|          1.0|    2|        1.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      0|          1.0|    2|        1.0|   3|       1.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          0.0|    2|        1.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          0.0|    2|        1.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          0.0|    2|        1.0|   2|       0.0|\n",
            "|  3|     3.0|  0|      0.0|      1|          0.0|    1|        0.0|   3|       1.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          0.0|    1|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      1|          0.0|    1|        0.0|   3|       1.0|\n",
            "|  2|     1.0|  0|      0.0|      0|          1.0|    2|        1.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      0|          1.0|    1|        0.0|   3|       1.0|\n",
            "|  3|     3.0|  0|      0.0|      1|          0.0|    2|        1.0|   3|       1.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          0.0|    2|        1.0|   2|       0.0|\n",
            "|  1|     2.0|  0|      0.0|      0|          1.0|    2|        1.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      0|          1.0|    2|        1.0|   3|       1.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          0.0|    1|        0.0|   1|       2.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          0.0|    2|        1.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      0|          1.0|    1|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      0|          1.0|    1|        0.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          0.0|    1|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      1|          0.0|    1|        0.0|   1|       2.0|\n",
            "+---+--------+---+---------+-------+-------------+-----+-----------+----+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "   ---------- Comprobamos que se han creado las columnas en df_DT_test -----------\n",
            "+---+--------+---+---------+-------+-------------+-----+-----------+----+----------+\n",
            "| cp|cp_index|fbs|fbs_index|restecg|restecg_index|slope|slope_index|thal|thal_index|\n",
            "+---+--------+---+---------+-------+-------------+-----+-----------+----+----------+\n",
            "|  1|     2.0|  0|      0.0|      0|          0.0|    2|        0.0|   2|       0.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      1|          1.0|    1|        1.0|   3|       1.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          1.0|    0|        2.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  0|      0.0|      1|          1.0|    2|        0.0|   3|       1.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  2|     1.0|  0|      0.0|      0|          0.0|    2|        0.0|   2|       0.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  1|     2.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  2|     1.0|  1|      1.0|      1|          1.0|    0|        2.0|   3|       1.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "|  0|     0.0|  1|      1.0|      0|          0.0|    1|        1.0|   3|       1.0|\n",
            "|  0|     0.0|  0|      0.0|      1|          1.0|    2|        0.0|   3|       1.0|\n",
            "|  0|     0.0|  0|      0.0|      0|          0.0|    1|        1.0|   3|       1.0|\n",
            "|  0|     0.0|  1|      1.0|      0|          0.0|    1|        1.0|   3|       1.0|\n",
            "|  2|     1.0|  0|      0.0|      1|          1.0|    2|        0.0|   2|       0.0|\n",
            "+---+--------+---+---------+-------+-------------+-----+-----------+----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 8: Aplicar VectorAssembler() sobre las columnas que no son ni las dos anteriores, ni la columna 'score_evaluation', devolviendo una columna llamada 'features'. Llamar al resultado DT_vector_assembler. ###"
      ],
      "metadata": {
        "id": "uoeCaEyIN5u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "print(\"   ---------- Imprimimos el esquema para ver cuales son las columnas a utilizar -----------\")\n",
        "print(df_DT_train.printSchema())\n",
        "\n",
        "DT_vector_assembler = VectorAssembler(\n",
        "    inputCols=[\"Additional_Number_of_Scoring\", \"Average_Score\", \"Review_Total_Negative_Word_Counts\", \"Total_Number_of_Reviews\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"days_since_review\", \"Review_Date_index\", \"Reviewer_Nationality_index\"],\n",
        "    outputCol=\"features\")"
      ],
      "metadata": {
        "id": "-dcpofOgN5u0",
        "outputId": "f4a4d46f-0e0c-48ce-c8d8-1f6494622f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Imprimimos el esquema para ver cuales son las columnas a utilizar -----------\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            " |-- cp_index: double (nullable = false)\n",
            " |-- fbs_index: double (nullable = false)\n",
            " |-- restecg_index: double (nullable = false)\n",
            " |-- slope_index: double (nullable = false)\n",
            " |-- thal_index: double (nullable = false)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 9: Aplicar el transformador sobre ambos dataframes. ###"
      ],
      "metadata": {
        "id": "Tjz7XFOTN5u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el VectorAssembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "        'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'\n",
        "    ],\n",
        "    outputCol='features'  # Nombre de la nueva columna vectorial\n",
        ")\n",
        "\n",
        "print(\"   ---------- Aplicamos el VectorAssembler a los DataFrames -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Z1MX5ZIzAl",
        "outputId": "1f113211-ee2d-44c1-8390-4a29db746ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Aplicamos el VectorAssembler a los DataFrames -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "# Aplicar el VectorAssembler a df_DT_train\n",
        "df_DT_train_assembled = assembler.transform(df_DT_train)\n",
        "\n",
        "# Aplicar el VectorAssembler a df_DT_test\n",
        "df_DT_test_assembled = assembler.transform(df_DT_test)\n",
        "\n",
        "print(\"   ---------- Vemos el DataFrame obtenido -----------\")\n",
        "df_DT_train_assembled.select(\"features\").show(10, truncate=False)\n",
        "\n",
        "print(\"   ---------- Vemos el DataFrame obtenido para df_DT_test -----------\")\n",
        "df_DT_test_assembled.select(\"features\").show(10, truncate=False)"
      ],
      "metadata": {
        "id": "2TUSm-DeN5u1",
        "outputId": "59a90f77-3784-4b9c-fd8a-94efa9cbe5fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Vemos el DataFrame obtenido -----------\n",
            "+---------------------------------------------------------------------------+\n",
            "|features                                                                   |\n",
            "+---------------------------------------------------------------------------+\n",
            "|[34.0,1.0,3.0,118.0,182.0,0.0,0.0,174.0,0.0,0.0,2.0,0.0,2.0]               |\n",
            "|[35.0,1.0,0.0,126.0,282.0,0.0,0.0,156.0,1.0,0.0,2.0,0.0,3.0]               |\n",
            "|[35.0,1.0,1.0,122.0,192.0,0.0,1.0,174.0,0.0,0.0,2.0,0.0,2.0]               |\n",
            "|[38.0,1.0,2.0,138.0,175.0,0.0,1.0,173.0,0.0,0.0,2.0,4.0,2.0]               |\n",
            "|[38.0,1.0,2.0,138.0,175.0,0.0,1.0,173.0,0.0,0.0,2.0,4.0,2.0]               |\n",
            "|[38.0,1.0,3.0,120.0,231.0,0.0,1.0,182.0,1.0,3.799999952316284,1.0,0.0,3.0] |\n",
            "|[39.0,0.0,2.0,138.0,220.0,0.0,1.0,152.0,0.0,0.0,1.0,0.0,2.0]               |\n",
            "|[39.0,1.0,0.0,118.0,219.0,0.0,1.0,140.0,0.0,1.2000000476837158,1.0,0.0,3.0]|\n",
            "|[39.0,1.0,2.0,140.0,321.0,0.0,0.0,182.0,0.0,0.0,2.0,0.0,2.0]               |\n",
            "|[40.0,1.0,0.0,110.0,167.0,0.0,0.0,114.0,1.0,2.0,1.0,0.0,3.0]               |\n",
            "+---------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "   ---------- Vemos el DataFrame obtenido para df_DT_test -----------\n",
            "+--------------------------------------------------------------------------+\n",
            "|features                                                                  |\n",
            "+--------------------------------------------------------------------------+\n",
            "|[29.0,1.0,1.0,130.0,204.0,0.0,0.0,202.0,0.0,0.0,2.0,0.0,2.0]              |\n",
            "|[34.0,0.0,1.0,118.0,210.0,0.0,1.0,192.0,0.0,0.699999988079071,2.0,0.0,2.0]|\n",
            "|[35.0,0.0,0.0,138.0,183.0,0.0,1.0,182.0,0.0,1.399999976158142,2.0,0.0,2.0]|\n",
            "|[35.0,1.0,0.0,120.0,198.0,0.0,1.0,130.0,1.0,1.600000023841858,1.0,0.0,3.0]|\n",
            "|[37.0,0.0,2.0,120.0,215.0,0.0,1.0,170.0,0.0,0.0,2.0,0.0,2.0]              |\n",
            "|[37.0,1.0,2.0,130.0,250.0,0.0,1.0,187.0,0.0,3.5,0.0,0.0,2.0]              |\n",
            "|[39.0,0.0,2.0,94.0,199.0,0.0,1.0,179.0,0.0,0.0,2.0,0.0,2.0]               |\n",
            "|[40.0,1.0,0.0,152.0,223.0,0.0,1.0,181.0,0.0,0.0,2.0,0.0,3.0]              |\n",
            "|[41.0,0.0,1.0,126.0,306.0,0.0,1.0,163.0,0.0,0.0,2.0,0.0,2.0]              |\n",
            "|[41.0,0.0,2.0,112.0,268.0,0.0,0.0,172.0,1.0,0.0,2.0,0.0,2.0]              |\n",
            "+--------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 10: Inicializar el modelo de árbol de decisión, entrenarlo y aplicarlo sobre los datos de test. ###\n",
        "* Modelo: DecisionTreeClassifier:\n",
        "  * Label: score_evaluation.\n",
        "  * Features: features.\n",
        "  * maxBins: 1000\n",
        "  * maxDepth: 1"
      ],
      "metadata": {
        "id": "hFw1PwU5N5u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Crear el árbol de decisión\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxBins=1000, maxDepth=5)\n",
        "\n",
        "# Crear el Pipeline\n",
        "pipeline = Pipeline(stages=[dt])\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "model = pipeline.fit(df_DT_train_assembled)\n",
        "\n",
        "print(\"   ---------- Aplicamos el modelo a los datos de TEST para obtener las previsiones y poder posteriormente evaluar el modelo -----------\")\n",
        "\n",
        "# Aplicar el modelo a los datos de prueba\n",
        "predictions = model.transform(df_DT_test_assembled)\n",
        "\n",
        "print(\"   ---------- Vemos resultados obtenidos -----------\")\n",
        "predictions.select(\"target\", \"features\", \"rawPrediction\", \"probability\", \"prediction\").show(100, truncate=False)\n"
      ],
      "metadata": {
        "id": "zlBmDoJVN5u1",
        "outputId": "8b892583-8e51-4f03-be62-5782096b5f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Aplicamos el modelo a los datos de TEST para obtener las previsiones y poder posteriormente evaluar el modelo -----------\n",
            "   ---------- Vemos resultados obtenidos -----------\n",
            "+------+----------------------------------------------------------------------------+-------------+----------------------------------------+----------+\n",
            "|target|features                                                                    |rawPrediction|probability                             |prediction|\n",
            "+------+----------------------------------------------------------------------------+-------------+----------------------------------------+----------+\n",
            "|1     |[29.0,1.0,1.0,130.0,204.0,0.0,0.0,202.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[34.0,0.0,1.0,118.0,210.0,0.0,1.0,192.0,0.0,0.699999988079071,2.0,0.0,2.0]  |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[35.0,0.0,0.0,138.0,183.0,0.0,1.0,182.0,0.0,1.399999976158142,2.0,0.0,2.0]  |[1.0,14.0]   |[0.06666666666666667,0.9333333333333333]|1.0       |\n",
            "|0     |[35.0,1.0,0.0,120.0,198.0,0.0,1.0,130.0,1.0,1.600000023841858,1.0,0.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[37.0,0.0,2.0,120.0,215.0,0.0,1.0,170.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[37.0,1.0,2.0,130.0,250.0,0.0,1.0,187.0,0.0,3.5,0.0,0.0,2.0]                |[7.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|1     |[39.0,0.0,2.0,94.0,199.0,0.0,1.0,179.0,0.0,0.0,2.0,0.0,2.0]                 |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[40.0,1.0,0.0,152.0,223.0,0.0,1.0,181.0,0.0,0.0,2.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[41.0,0.0,1.0,126.0,306.0,0.0,1.0,163.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[41.0,0.0,2.0,112.0,268.0,0.0,0.0,172.0,1.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[41.0,1.0,1.0,110.0,235.0,0.0,1.0,153.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[41.0,1.0,1.0,120.0,157.0,0.0,1.0,182.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[42.0,1.0,1.0,120.0,295.0,0.0,1.0,162.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[42.0,1.0,2.0,120.0,240.0,1.0,1.0,194.0,0.0,0.800000011920929,0.0,0.0,3.0]  |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[42.0,1.0,2.0,130.0,180.0,0.0,1.0,150.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[43.0,0.0,0.0,132.0,341.0,1.0,0.0,136.0,1.0,3.0,1.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[43.0,1.0,0.0,110.0,211.0,0.0,1.0,161.0,0.0,0.0,2.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[43.0,1.0,0.0,120.0,177.0,0.0,0.0,120.0,1.0,2.5,1.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[43.0,1.0,0.0,132.0,247.0,1.0,0.0,143.0,1.0,0.10000000149011612,1.0,4.0,3.0]|[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[43.0,1.0,2.0,130.0,315.0,0.0,1.0,162.0,0.0,1.899999976158142,2.0,1.0,2.0]  |[7.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|1     |[44.0,0.0,2.0,118.0,242.0,0.0,1.0,149.0,0.0,0.30000001192092896,1.0,1.0,2.0]|[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[44.0,1.0,1.0,120.0,220.0,0.0,1.0,170.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[44.0,1.0,2.0,130.0,233.0,0.0,1.0,179.0,1.0,0.4000000059604645,2.0,0.0,2.0] |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[44.0,1.0,2.0,140.0,235.0,0.0,0.0,180.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[45.0,0.0,0.0,138.0,236.0,0.0,0.0,152.0,1.0,0.20000000298023224,1.0,0.0,2.0]|[5.0,2.0]    |[0.7142857142857143,0.2857142857142857] |0.0       |\n",
            "|1     |[45.0,0.0,1.0,130.0,234.0,0.0,0.0,175.0,0.0,0.6000000238418579,1.0,0.0,2.0] |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |(13,[0,1,3,4,7,10,12],[45.0,1.0,115.0,260.0,185.0,2.0,2.0])                 |[1.0,14.0]   |[0.06666666666666667,0.9333333333333333]|1.0       |\n",
            "|0     |[45.0,1.0,0.0,142.0,309.0,0.0,0.0,147.0,1.0,0.0,1.0,3.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[45.0,1.0,3.0,110.0,264.0,0.0,1.0,132.0,0.0,1.2000000476837158,1.0,0.0,3.0] |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |(13,[0,3,4,7,8,10,12],[46.0,138.0,243.0,152.0,1.0,1.0,2.0])                 |[5.0,2.0]    |[0.7142857142857143,0.2857142857142857] |0.0       |\n",
            "|1     |[46.0,0.0,1.0,105.0,204.0,0.0,1.0,172.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[47.0,1.0,2.0,108.0,243.0,0.0,1.0,152.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[47.0,1.0,2.0,130.0,253.0,0.0,1.0,179.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[47.0,1.0,2.0,138.0,257.0,0.0,0.0,156.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |(13,[0,1,3,4,7,10,12],[48.0,1.0,122.0,222.0,186.0,2.0,2.0])                 |[1.0,14.0]   |[0.06666666666666667,0.9333333333333333]|1.0       |\n",
            "|0     |[48.0,1.0,1.0,110.0,229.0,0.0,1.0,168.0,0.0,1.0,0.0,0.0,3.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[48.0,1.0,2.0,124.0,255.0,1.0,1.0,175.0,0.0,0.0,2.0,2.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[49.0,1.0,1.0,130.0,266.0,0.0,1.0,171.0,0.0,0.6000000238418579,2.0,0.0,2.0] |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[49.0,1.0,2.0,118.0,149.0,0.0,0.0,126.0,0.0,0.800000011920929,2.0,3.0,2.0]  |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[49.0,1.0,2.0,120.0,188.0,0.0,1.0,139.0,0.0,2.0,1.0,3.0,3.0]                |[1.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|1     |[50.0,0.0,1.0,120.0,244.0,0.0,1.0,162.0,0.0,1.100000023841858,2.0,0.0,2.0]  |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[50.0,1.0,2.0,140.0,233.0,0.0,1.0,163.0,0.0,0.6000000238418579,1.0,1.0,3.0] |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[51.0,0.0,2.0,140.0,308.0,0.0,0.0,142.0,0.0,1.5,2.0,1.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[51.0,1.0,0.0,140.0,261.0,0.0,0.0,186.0,1.0,0.0,2.0,0.0,2.0]                |[5.0,2.0]    |[0.7142857142857143,0.2857142857142857] |0.0       |\n",
            "|0     |[51.0,1.0,0.0,140.0,298.0,0.0,1.0,122.0,1.0,4.199999809265137,1.0,3.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[51.0,1.0,2.0,110.0,175.0,0.0,1.0,123.0,0.0,0.6000000238418579,2.0,0.0,2.0] |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[51.0,1.0,2.0,125.0,245.0,1.0,0.0,166.0,0.0,2.4000000953674316,1.0,0.0,2.0] |[7.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|1     |[52.0,1.0,0.0,108.0,233.0,1.0,1.0,147.0,0.0,0.10000000149011612,2.0,3.0,3.0]|[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[52.0,1.0,0.0,125.0,212.0,0.0,1.0,168.0,0.0,1.0,2.0,2.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[52.0,1.0,0.0,128.0,255.0,0.0,1.0,161.0,1.0,0.0,2.0,1.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[52.0,1.0,1.0,120.0,325.0,0.0,1.0,172.0,0.0,0.20000000298023224,2.0,0.0,2.0]|[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[52.0,1.0,1.0,128.0,205.0,1.0,1.0,184.0,0.0,0.0,2.0,0.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[53.0,1.0,0.0,123.0,282.0,0.0,1.0,95.0,1.0,2.0,1.0,2.0,3.0]                 |[2.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|0     |[53.0,1.0,0.0,140.0,203.0,1.0,0.0,155.0,1.0,3.0999999046325684,0.0,0.0,3.0] |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[53.0,1.0,0.0,142.0,226.0,0.0,0.0,111.0,1.0,0.0,2.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[54.0,0.0,2.0,110.0,214.0,0.0,1.0,158.0,0.0,1.600000023841858,1.0,0.0,2.0]  |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|1     |[54.0,0.0,2.0,160.0,201.0,0.0,1.0,163.0,0.0,0.0,2.0,1.0,2.0]                |[0.0,51.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[54.0,1.0,0.0,110.0,206.0,0.0,0.0,108.0,1.0,0.0,1.0,1.0,2.0]                |[12.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[54.0,1.0,0.0,110.0,239.0,0.0,1.0,126.0,1.0,2.799999952316284,1.0,1.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[54.0,1.0,0.0,122.0,286.0,0.0,0.0,116.0,1.0,3.200000047683716,1.0,2.0,2.0]  |[12.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[54.0,1.0,0.0,124.0,266.0,0.0,0.0,109.0,1.0,2.200000047683716,1.0,1.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[55.0,0.0,0.0,180.0,327.0,0.0,2.0,117.0,1.0,3.4000000953674316,1.0,0.0,2.0] |[5.0,2.0]    |[0.7142857142857143,0.2857142857142857] |0.0       |\n",
            "|0     |[55.0,1.0,0.0,140.0,217.0,0.0,1.0,111.0,1.0,5.599999904632568,0.0,0.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[55.0,1.0,0.0,160.0,289.0,0.0,0.0,145.0,1.0,0.800000011920929,1.0,1.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[56.0,1.0,0.0,130.0,283.0,1.0,0.0,103.0,1.0,1.600000023841858,0.0,0.0,3.0]  |[2.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|0     |[56.0,1.0,0.0,132.0,184.0,0.0,0.0,105.0,1.0,2.0999999046325684,1.0,1.0,1.0] |[12.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[56.0,1.0,1.0,130.0,221.0,0.0,0.0,163.0,0.0,0.0,2.0,0.0,3.0]                |[4.0,11.0]   |[0.26666666666666666,0.7333333333333333]|1.0       |\n",
            "|1     |[56.0,1.0,3.0,120.0,193.0,0.0,0.0,162.0,0.0,1.899999976158142,1.0,0.0,3.0]  |[1.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|0     |[57.0,0.0,1.0,130.0,236.0,0.0,0.0,174.0,0.0,0.0,1.0,1.0,2.0]                |[0.0,15.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[57.0,1.0,0.0,110.0,335.0,0.0,1.0,143.0,1.0,3.0,1.0,1.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[57.0,1.0,0.0,132.0,207.0,0.0,1.0,168.0,1.0,0.0,2.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[58.0,0.0,0.0,130.0,197.0,0.0,1.0,131.0,0.0,0.6000000238418579,1.0,0.0,2.0] |[1.0,14.0]   |[0.06666666666666667,0.9333333333333333]|1.0       |\n",
            "|0     |[58.0,0.0,1.0,136.0,319.0,1.0,0.0,152.0,0.0,0.0,2.0,2.0,2.0]                |[0.0,15.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[58.0,1.0,0.0,114.0,318.0,0.0,2.0,140.0,0.0,4.400000095367432,0.0,3.0,1.0]  |[12.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[58.0,1.0,0.0,128.0,216.0,0.0,0.0,131.0,1.0,2.200000047683716,1.0,3.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[58.0,1.0,0.0,128.0,259.0,0.0,0.0,130.0,1.0,3.0,1.0,2.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[58.0,1.0,0.0,146.0,218.0,0.0,1.0,105.0,0.0,2.0,1.0,1.0,3.0]                |[2.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|1     |[58.0,1.0,2.0,105.0,240.0,0.0,0.0,154.0,1.0,0.6000000238418579,1.0,0.0,3.0] |[4.0,11.0]   |[0.26666666666666666,0.7333333333333333]|1.0       |\n",
            "|0     |[58.0,1.0,2.0,132.0,224.0,0.0,0.0,173.0,0.0,3.200000047683716,2.0,2.0,3.0]  |[0.0,2.0]    |[0.0,1.0]                               |1.0       |\n",
            "|1     |[59.0,1.0,0.0,135.0,234.0,0.0,1.0,161.0,0.0,0.5,1.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |(13,[0,1,3,4,7,10,12],[59.0,1.0,138.0,271.0,182.0,2.0,2.0])                 |[1.0,14.0]   |[0.06666666666666667,0.9333333333333333]|1.0       |\n",
            "|0     |[59.0,1.0,0.0,164.0,176.0,1.0,0.0,90.0,0.0,1.0,1.0,2.0,1.0]                 |[12.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[59.0,1.0,2.0,150.0,212.0,1.0,1.0,157.0,0.0,1.600000023841858,2.0,0.0,2.0]  |[4.0,11.0]   |[0.26666666666666666,0.7333333333333333]|1.0       |\n",
            "|1     |[59.0,1.0,3.0,178.0,270.0,0.0,0.0,145.0,0.0,4.199999809265137,0.0,0.0,3.0]  |[7.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|0     |[60.0,0.0,0.0,150.0,258.0,0.0,0.0,157.0,0.0,2.5999999046325684,1.0,2.0,3.0] |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |[60.0,0.0,2.0,120.0,178.0,1.0,1.0,96.0,0.0,0.0,2.0,0.0,2.0]                 |[1.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|0     |[60.0,1.0,0.0,117.0,230.0,1.0,1.0,160.0,1.0,1.399999976158142,2.0,2.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[60.0,1.0,0.0,125.0,258.0,0.0,0.0,141.0,1.0,2.799999952316284,1.0,1.0,3.0]  |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[60.0,1.0,0.0,130.0,206.0,0.0,0.0,132.0,1.0,2.4000000953674316,1.0,2.0,3.0] |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[60.0,1.0,2.0,140.0,185.0,0.0,0.0,155.0,0.0,3.0,1.0,0.0,2.0]                |[0.0,2.0]    |[0.0,1.0]                               |1.0       |\n",
            "|0     |[61.0,0.0,0.0,145.0,307.0,0.0,0.0,146.0,1.0,1.0,1.0,0.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[62.0,0.0,0.0,138.0,294.0,1.0,1.0,106.0,0.0,1.899999976158142,1.0,3.0,2.0]  |[3.0,1.0]    |[0.75,0.25]                             |0.0       |\n",
            "|1     |(13,[0,3,4,7,9,10,12],[62.0,140.0,394.0,157.0,1.2000000476837158,1.0,2.0])  |[1.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|0     |[62.0,1.0,1.0,120.0,281.0,0.0,0.0,103.0,0.0,1.399999976158142,1.0,1.0,3.0]  |[6.0,0.0]    |[1.0,0.0]                               |0.0       |\n",
            "|1     |[62.0,1.0,1.0,128.0,208.0,1.0,0.0,140.0,0.0,0.0,2.0,0.0,2.0]                |[4.0,11.0]   |[0.26666666666666666,0.7333333333333333]|1.0       |\n",
            "|0     |[63.0,0.0,0.0,124.0,197.0,0.0,1.0,136.0,1.0,0.0,1.0,0.0,2.0]                |[5.0,2.0]    |[0.7142857142857143,0.2857142857142857] |0.0       |\n",
            "|0     |[63.0,0.0,0.0,150.0,407.0,0.0,0.0,154.0,0.0,4.0,1.0,3.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|1     |(13,[0,2,3,4,7,10,12],[63.0,2.0,135.0,252.0,172.0,2.0,2.0])                 |[0.0,15.0]   |[0.0,1.0]                               |1.0       |\n",
            "|0     |[63.0,1.0,0.0,130.0,330.0,1.0,0.0,132.0,1.0,1.7999999523162842,2.0,3.0,3.0] |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "|0     |[63.0,1.0,0.0,140.0,187.0,0.0,0.0,144.0,1.0,4.0,2.0,2.0,3.0]                |[41.0,0.0]   |[1.0,0.0]                               |0.0       |\n",
            "+------+----------------------------------------------------------------------------+-------------+----------------------------------------+----------+\n",
            "only showing top 100 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 11: Evaluar el modelo aplicándole un clasificador multiclase. Calcular la métrica 'accuracy', y conseguir el complementario para calcular el error. ###\n",
        "* Evaluador: MulticlassClassificationEvaluator\n",
        "  * Label: score_evaluation.\n",
        "  * Prediction: prediction.\n",
        "  * MetricName: accuracy."
      ],
      "metadata": {
        "id": "J1rkDFx3N5u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Crear el evaluador de clasificación multiclase\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"target\",       # Cambiado de \"score_evaluation\" a \"target\"\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "# Evaluar el modelo en los datos de prueba\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"   ---------- Vemos el error obtenido -----------\")\n",
        "print(\"Error en el test = %g \" % (1.0 - accuracy))\n"
      ],
      "metadata": {
        "id": "oBBCWJbSN5u2",
        "outputId": "7b0dc596-30d1-484b-ffb7-a03a975f0efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Vemos el error obtenido -----------\n",
            "Error en el test = 0.252174 \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark ML: Pipelines ##"
      ],
      "metadata": {
        "id": "cD8ZWhCSN5u7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipelines: Árboles de Decisión ###\n",
        "Con el mismo concepto que con el KMeans, se va a diseñar el flujo para los árboles de decisión. Primero hay que aplicar los cambios de preprocesamiento vistos anteriormente al DataFrame inicial para preparalo."
      ],
      "metadata": {
        "id": "GoNZEIF2N5u7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 12: Eliminar, de los dataframes df_spark_sql_train y df_spark_sql test, las variables 'Hotel_Address', 'Hotel_Name', 'Tags', 'Positive Review', 'Negative_Review' y 'score_string'. Llamarlos: df_DT_train y df_DT_test. ###"
      ],
      "metadata": {
        "id": "yG6KJ5VVN5u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "# Hecho en un punto anterior\n",
        "# df_DT_train = df_spark_sql_train.drop('Hotel_Address', 'Hotel_Name', 'Tags', 'Positive_Review', 'Negative_Review', 'score_string')\n",
        "print(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\")\n",
        "print(df_DT_train.printSchema())\n",
        "print(\"   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\")\n",
        "print(df_DT_test.printSchema())"
      ],
      "metadata": {
        "id": "VhGBSwtPN5u7",
        "outputId": "13c75319-a876-4492-ebd8-8c4e03faac37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Comprobamos que se han eliminado las columnas de df_DT_train -----------\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            " |-- cp_index: double (nullable = false)\n",
            " |-- fbs_index: double (nullable = false)\n",
            " |-- restecg_index: double (nullable = false)\n",
            " |-- slope_index: double (nullable = false)\n",
            " |-- thal_index: double (nullable = false)\n",
            "\n",
            "None\n",
            "   ---------- Comprobamos que se han eliminado las columnas de df_DT_test -----------\n",
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: float (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- target: integer (nullable = true)\n",
            " |-- score_evaluation: integer (nullable = true)\n",
            " |-- rounded_oldpeak: integer (nullable = true)\n",
            " |-- cp_index: double (nullable = false)\n",
            " |-- fbs_index: double (nullable = false)\n",
            " |-- restecg_index: double (nullable = false)\n",
            " |-- slope_index: double (nullable = false)\n",
            " |-- thal_index: double (nullable = false)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después se diseña el flujo para este modelo, el cual será:\n",
        "\n",
        "** StringIndexer --> VectorAssembler --> Decission Tree (Inicialización) --> Decission Tree (Entrenamiento) --> Modelo Decission Tree entrenado **"
      ],
      "metadata": {
        "id": "cPkLbg9VN5u7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 13: Recoger una lista con todos los StringIndexer a aplicar, y llamarla DT_string_indexers ###\n",
        " En lugar de sobreescribir cada vez el dataframe, crear una lista, y con el método 'append', se irán añadiendo todos los StringIndexers()."
      ],
      "metadata": {
        "id": "RRpVE2UMN5u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "\n",
        "# Lista para almacenar los indexadores\n",
        "DT_string_indexers = []\n",
        "\n",
        "# Definir un StringIndexer para cada columna de tipo string\n",
        "for name, dtype in df_DT_train.dtypes:\n",
        "    if dtype == \"string\":\n",
        "        print(\"   ---------- Definimos indexer para la columna: \", name)\n",
        "        DT_string_indexers.append(StringIndexer(inputCol=name, outputCol=name+\"_index2\"))\n",
        "\n",
        "# Mostrar la lista de indexadores definidos\n",
        "print(\"   ---------- Indexers definidos: -----------\")\n",
        "for indexer in DT_string_indexers:\n",
        "    print(indexer)"
      ],
      "metadata": {
        "id": "dJxmRH67N5u8",
        "outputId": "60769f6b-8971-4cb2-ba45-8aac16fb4575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Indexers definidos: -----------\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 14: Guardar en la variable 'DT_vector_assembler' la aplicación del mismo VectorAssembler() del ejercicio 8. ###"
      ],
      "metadata": {
        "id": "8rNn4NNKN5u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "DT_vector_assembler = VectorAssembler(\n",
        "    inputCols=[\"Additional_Number_of_Scoring\", \"Average_Score\", \"Review_Total_Negative_Word_Counts\", \"Total_Number_of_Reviews\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"days_since_review\", \"Review_Date_index2\", \"Reviewer_Nationality_index2\"],\n",
        "    outputCol=\"features\")"
      ],
      "metadata": {
        "id": "nybACkHFN5u8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 15: Crear una lista con el mombre de DT_pipeline_stages, y añadirle la lista de StringIndexers y el VectorAssembler (en este orden) ###"
      ],
      "metadata": {
        "id": "xZrLEej2N5u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "DT_pipeline_stages = []\n",
        "# Añadir la lista de String Indexers\n",
        "DT_pipeline_stages = [str_indexer for str_indexer in DT_string_indexers]\n",
        "DT_pipeline_stages.append(DT_vector_assembler)\n"
      ],
      "metadata": {
        "id": "FpLZbnPgN5u9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 16: Inicializar el modelo de árbol de decisión (mismas especificaciones que en el ej. 10), y añadirlo a la lista de pasos 'DT_pipeline_stages' ###"
      ],
      "metadata": {
        "id": "vw4Y1dnQN5u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir aquí el ejercicio\n",
        "print(\"   ---------- Creamos el arbol de decision para la columna score_evaluation y entrenamos el modelo con los datos TRAIN -----------\")\n",
        "dt_pipeline = DecisionTreeClassifier(labelCol=\"score_evaluation\", featuresCol=\"features\", maxBins=1000, maxDepth=1)\n",
        "DT_pipeline_stages.append(dt_pipeline)\n"
      ],
      "metadata": {
        "id": "l2BEmHLfN5u9",
        "outputId": "6e08e463-1c65-415a-d192-0d99f1d75235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Creamos el arbol de decision para la columna score_evaluation y entrenamos el modelo con los datos TRAIN -----------\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 17: Diseñar el Pipeline y aplicarlo sobre los datos de Train, llamándolo 'DT_pipeline_model' ###"
      ],
      "metadata": {
        "id": "KlSk9SsRN5u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "zwxa0fIoLCPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los StringIndexers para columnas categóricas, solo si no existen ya\n",
        "string_indexers = [\n",
        "    StringIndexer(inputCol=\"cp\", outputCol=\"cp_index\"),\n",
        "    StringIndexer(inputCol=\"fbs\", outputCol=\"fbs_index\"),\n",
        "    StringIndexer(inputCol=\"restecg\", outputCol=\"restecg_index\"),\n",
        "    StringIndexer(inputCol=\"slope\", outputCol=\"slope_index\"),\n",
        "    StringIndexer(inputCol=\"thal\", outputCol=\"thal_index\")\n",
        "]\n",
        "\n",
        "# Definir el VectorAssembler para combinar las características\n",
        "vector_assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        'age', 'sex', 'cp_index', 'trestbps', 'chol', 'fbs_index', 'restecg_index',\n",
        "        'thalach', 'exang', 'oldpeak', 'slope_index', 'ca', 'thal_index'\n",
        "    ],\n",
        "    outputCol='features'\n",
        ")\n",
        "\n",
        "# Definir el clasificador de árbol de decisión\n",
        "dt_classifier = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxBins=1000, maxDepth=5)\n",
        "\n",
        "# Crear una lista de etapas para el Pipeline\n",
        "DT_pipeline_stages = string_indexers + [vector_assembler, dt_classifier]\n",
        "\n",
        "# Definir el Pipeline a partir de las etapas anteriores\n",
        "DT_pipeline = Pipeline(stages=DT_pipeline_stages)\n",
        "\n",
        "# Aplicar el Pipeline sobre los datos TRAIN\n",
        "# Verificar si las columnas ya existen antes de aplicar el Pipeline\n",
        "for indexer in string_indexers:\n",
        "    indexer_col = indexer.getOutputCol()\n",
        "    if indexer_col in df_DT_train.columns:\n",
        "        df_DT_train = df_DT_train.drop(indexer_col)\n",
        "\n",
        "DT_pipeline_model = DT_pipeline.fit(df_DT_train)\n",
        "\n",
        "# Mostrar el modelo de árbol de decisión entrenado\n",
        "print(\"   ---------- Modelo de árbol de decisión entrenado -----------\")\n",
        "print(DT_pipeline_model.stages[-1])  # Muestra el clasificador de árbol de decisión"
      ],
      "metadata": {
        "id": "k-DSwAPQN5u-",
        "outputId": "f6f1e129-2068-4fc4-c65d-1e49141db7c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---------- Modelo de árbol de decisión entrenado -----------\n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_b189c13f562a, depth=5, numNodes=45, numClasses=2, numFeatures=13\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 18: Aplicar el modelo resultante sobre los datos de test y evaluarlo al igual que se hizo en el ej. 11 ###"
      ],
      "metadata": {
        "id": "s1EcEPqRN5u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Verificar y eliminar columnas existentes que puedan causar conflictos\n",
        "indexer_output_cols = ['cp_index', 'fbs_index', 'restecg_index', 'slope_index', 'thal_index']\n",
        "\n",
        "# Eliminar columnas si existen en df_DT_test\n",
        "for col_name in indexer_output_cols:\n",
        "    if col_name in df_DT_test.columns:\n",
        "        df_DT_test = df_DT_test.drop(col_name)\n",
        "\n",
        "# Aplicar el modelo al conjunto de datos de prueba\n",
        "DT_predictions = DT_pipeline_model.transform(df_DT_test)\n",
        "\n",
        "# Mostrar algunas predicciones\n",
        "DT_predictions.select(\"target\", \"features\", \"rawPrediction\", \"probability\", \"prediction\").show(100)\n",
        "\n",
        "# Mostrar los tipos de datos de las columnas en el DataFrame de predicciones\n",
        "print(\"Tipos de datos en 'DT_predictions':\")\n",
        "print(DT_predictions.dtypes)\n",
        "\n",
        "# Mostrar el tipo de los objetos 'DT_predictions'\n",
        "print(\"Tipo de 'DT_predictions':\")\n",
        "print(type(DT_predictions))\n",
        "\n",
        "# Obtener el modelo de árbol de decisión entrenado desde el Pipeline\n",
        "dtModel = DT_pipeline_model.stages[-1]\n",
        "\n",
        "# Definir el evaluador para evaluar el modelo\n",
        "evaluator2 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "# Evaluar el modelo y calcular la precisión\n",
        "accuracy2 = evaluator2.evaluate(DT_predictions)\n",
        "print(\"   ---------- Vemos error obtenido -----------\")\n",
        "print(\"Error en el test = %g \" % (1.0 - accuracy2))\n"
      ],
      "metadata": {
        "id": "7zDQiiYzN5u-",
        "outputId": "6d3de360-057a-4dc4-cca8-b4ce8734bf3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+-------------+--------------------+----------+\n",
            "|target|            features|rawPrediction|         probability|prediction|\n",
            "+------+--------------------+-------------+--------------------+----------+\n",
            "|     1|[29.0,1.0,2.0,130...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,2,3,4,7,9,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,3,4,7,9,10...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[35.0,1.0,0.0,120...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,2,3,4,7,10...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[37.0,1.0,1.0,130...|    [0.0,1.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|(13,[0,2,3,4,7,10...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|(13,[0,1,3,4,7,10...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,2,3,4,7,10...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[41.0,0.0,1.0,112...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[42.0,1.0,1.0,120...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[43.0,0.0,0.0,132...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,1,3,4,7,10...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[43.0,1.0,0.0,120...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[43.0,1.0,0.0,132...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[43.0,1.0,1.0,130...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,2,3,4,7,9,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[44.0,1.0,1.0,130...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[44.0,1.0,1.0,140...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,3,4,6,7,8,...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|(13,[0,2,3,4,6,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,3,4,6,7,...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[45.0,1.0,0.0,142...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[45.0,1.0,3.0,110...|   [0.0,11.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|(13,[0,3,4,6,7,8]...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|(13,[0,2,3,4,7,10...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,2,3,4,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[47.0,1.0,1.0,138...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,1,3,4,6,7,...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[48.0,1.0,2.0,110...|   [0.0,11.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|[48.0,1.0,1.0,124...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[49.0,1.0,2.0,130...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[49.0,1.0,1.0,118...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[49.0,1.0,1.0,120...|   [0.0,11.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|(13,[0,2,3,4,7,9,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[50.0,1.0,1.0,140...|   [0.0,11.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|[51.0,0.0,1.0,140...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[51.0,1.0,0.0,140...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[51.0,1.0,0.0,140...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[51.0,1.0,1.0,110...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[51.0,1.0,1.0,125...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[52.0,1.0,0.0,108...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[52.0,1.0,0.0,125...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[52.0,1.0,0.0,128...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[52.0,1.0,2.0,120...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[52.0,1.0,2.0,128...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[53.0,1.0,0.0,123...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[53.0,1.0,0.0,140...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[53.0,1.0,0.0,142...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,2,3,4,7,9]...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|(13,[0,2,3,4,7,10...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[54.0,1.0,0.0,110...|   [11.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[54.0,1.0,0.0,110...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[54.0,1.0,0.0,122...|   [11.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[54.0,1.0,0.0,124...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|(13,[0,3,4,6,7,8,...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[55.0,1.0,0.0,140...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[55.0,1.0,0.0,160...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[56.0,1.0,0.0,130...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[56.0,1.0,0.0,132...|    [0.0,2.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|[56.0,1.0,2.0,130...|    [0.0,3.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|[56.0,1.0,3.0,120...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|(13,[0,2,3,4,6,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[57.0,1.0,0.0,110...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[57.0,1.0,0.0,132...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,3,4,7,9],[...|   [0.0,15.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[58.0,0.0,2.0,136...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[58.0,1.0,0.0,114...|    [3.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[58.0,1.0,0.0,128...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[58.0,1.0,0.0,128...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[58.0,1.0,0.0,146...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|[58.0,1.0,1.0,105...|   [10.0,1.0]|[0.90909090909090...|       0.0|\n",
            "|     0|[58.0,1.0,1.0,132...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,1,3,4,7,9,...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,1,3,4,6,7,...|    [5.0,2.0]|[0.71428571428571...|       0.0|\n",
            "|     0|[59.0,1.0,0.0,164...|    [0.0,2.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|[59.0,1.0,1.0,150...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     1|[59.0,1.0,3.0,178...|   [10.0,1.0]|[0.90909090909090...|       0.0|\n",
            "|     0|[60.0,0.0,0.0,150...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,2,3,4,5,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[60.0,1.0,0.0,117...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[60.0,1.0,0.0,125...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[60.0,1.0,0.0,130...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[60.0,1.0,1.0,140...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[61.0,0.0,0.0,145...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|(13,[0,3,4,5,7,9,...|    [0.0,3.0]|           [0.0,1.0]|       1.0|\n",
            "|     1|(13,[0,3,4,6,7,9]...|    [5.0,2.0]|[0.71428571428571...|       0.0|\n",
            "|     0|[62.0,1.0,2.0,120...|   [10.0,1.0]|[0.90909090909090...|       0.0|\n",
            "|     1|[62.0,1.0,2.0,128...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|(13,[0,3,4,7,8],[...|    [0.0,3.0]|           [0.0,1.0]|       1.0|\n",
            "|     0|[63.0,0.0,0.0,150...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     1|(13,[0,2,3,4,6,7,...|   [2.0,55.0]|[0.03508771929824...|       1.0|\n",
            "|     0|[63.0,1.0,0.0,130...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|     0|[63.0,1.0,0.0,140...|   [42.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "+------+--------------------+-------------+--------------------+----------+\n",
            "only showing top 100 rows\n",
            "\n",
            "Tipos de datos en 'DT_predictions':\n",
            "[('age', 'int'), ('sex', 'int'), ('cp', 'int'), ('trestbps', 'int'), ('chol', 'int'), ('fbs', 'int'), ('restecg', 'int'), ('thalach', 'int'), ('exang', 'int'), ('oldpeak', 'float'), ('slope', 'int'), ('ca', 'int'), ('thal', 'int'), ('target', 'int'), ('score_evaluation', 'int'), ('rounded_oldpeak', 'int'), ('cp_index', 'double'), ('fbs_index', 'double'), ('restecg_index', 'double'), ('slope_index', 'double'), ('thal_index', 'double'), ('features', 'vector'), ('rawPrediction', 'vector'), ('probability', 'vector'), ('prediction', 'double')]\n",
            "Tipo de 'DT_predictions':\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "   ---------- Vemos error obtenido -----------\n",
            "Error en el test = 0.278261 \n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "name": "AnaliticaEscalablePySparkEjercicios",
    "notebookId": 4027673054087821,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}